{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa4fb0d8-74d4-414e-a41c-f2178a46b79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.utils as utils\n",
    "import torch\n",
    "from torch import autocast\n",
    "from diffusers import StableDiffusionPipeline, DDIMScheduler\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from IPython.display import display\n",
    "from slugify import slugify\n",
    "from huggingface_hub import HfApi, HfFolder, CommitOperationAdd\n",
    "from huggingface_hub import create_repo\n",
    "from IPython.display import display_markdown\n",
    "from IPython.display import clear_output\n",
    "from IPython.utils import capture\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "581add08-89b5-492e-8e7d-fca08c8ec4e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Workspace Setup Complete ===\n"
     ]
    }
   ],
   "source": [
    "utils.setup_workspace(config_file=\"src/configs/workspace_config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0df5aba5-ed12-4e4b-8e50-1cadba6fd760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t`--num_processes` was set to a value of `1`\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--mixed_precision` was set to a value of `'no'`\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "For effortless bug reporting copy-paste your error into this form: https://docs.google.com/forms/d/e/1FAIpQLScPB8emS3Thkp66nvqwmjTEgxp8Y9ufuWTzFyr9kJ5AoI47dQ/viewform?usp=sf_link\n",
      "================================================================================\n",
      "/usr/local/lib/python3.9/dist-packages/bitsandbytes/cuda_setup/paths.py:27: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/usr/local/nvidia/lib'), PosixPath('/usr/local/nvidia/lib64')}\n",
      "  warn(\n",
      "/usr/local/lib/python3.9/dist-packages/bitsandbytes/cuda_setup/paths.py:105: UserWarning: /usr/local/nvidia/lib:/usr/local/nvidia/lib64 did not contain libcudart.so as expected! Searching further paths...\n",
      "  warn(\n",
      "/usr/local/lib/python3.9/dist-packages/bitsandbytes/cuda_setup/paths.py:27: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('443'), PosixPath('tcp'), PosixPath('//10.43.0.1')}\n",
      "  warn(\n",
      "/usr/local/lib/python3.9/dist-packages/bitsandbytes/cuda_setup/paths.py:27: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//matplotlib_inline.backend_inline'), PosixPath('module')}\n",
      "  warn(\n",
      "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching /usr/local/cuda/lib64...\n",
      "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.6\n",
      "CUDA SETUP: Detected CUDA version 112\n",
      "CUDA SETUP: Loading binary /usr/local/lib/python3.9/dist-packages/bitsandbytes/libbitsandbytes_cuda112.so...\n",
      "/usr/local/lib/python3.9/dist-packages/diffusers/utils/deprecation_utils.py:35: FutureWarning: It is deprecated to pass a pretrained model name or path to `from_config`.If you were trying to load a scheduler, please use <class 'diffusers.schedulers.scheduling_ddpm.DDPMScheduler'>.from_pretrained(...) instead. Otherwise, please make sure to pass a configuration dictionary instead. This functionality will be removed in v1.0.0.\n",
      "  warnings.warn(warning + message, FutureWarning)\n",
      "Caching latents: 100%|████████████████████████| 100/100 [00:11<00:00,  8.58it/s]\n",
      "Steps:  50%|██████      | 500/1000 [02:54<02:50,  2.93it/s, loss=0.254, lr=1e-6]\n",
      "Fetching 15 files: 100%|█████████████████████| 15/15 [00:00<00:00, 28532.68it/s]\u001b[A\n",
      "/usr/local/lib/python3.9/dist-packages/diffusers/utils/deprecation_utils.py:35: FutureWarning: The configuration file of this scheduler: DDIMScheduler {\n",
      "  \"_class_name\": \"DDIMScheduler\",\n",
      "  \"_diffusers_version\": \"0.9.0\",\n",
      "  \"beta_end\": 0.012,\n",
      "  \"beta_schedule\": \"scaled_linear\",\n",
      "  \"beta_start\": 0.00085,\n",
      "  \"clip_sample\": false,\n",
      "  \"num_train_timesteps\": 1000,\n",
      "  \"prediction_type\": \"epsilon\",\n",
      "  \"set_alpha_to_one\": false,\n",
      "  \"steps_offset\": 0,\n",
      "  \"trained_betas\": null\n",
      "}\n",
      " is outdated. `steps_offset` should be set to 1 instead of 0. Please make sure to update the config accordingly as leaving `steps_offset` might led to incorrect results in future versions. If you have downloaded this checkpoint from the Hugging Face Hub, it would be very nice if you could open a Pull request for the `scheduler/scheduler_config.json` file\n",
      "  warnings.warn(warning + message, FutureWarning)\n",
      "[*] Weights saved at ./weights/500\n",
      "Steps: 100%|███████████| 1000/1000 [06:41<00:00,  2.92it/s, loss=0.245, lr=1e-6]\n",
      "Fetching 15 files: 100%|█████████████████████| 15/15 [00:00<00:00, 32280.43it/s]\u001b[A\n",
      "[*] Weights saved at ./weights/1000\n",
      "Steps: 100%|███████████| 1000/1000 [07:25<00:00,  2.24it/s, loss=0.245, lr=1e-6]\n"
     ]
    }
   ],
   "source": [
    "!accelerate launch src/train_dreambooth.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca169cd6-ccf1-4e6f-a7ee-fc4a52c086c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"weights/1000/\"\n",
    "\n",
    "scheduler = DDIMScheduler(beta_start=0.00085, beta_end=0.012, beta_schedule=\"scaled_linear\", clip_sample=False, set_alpha_to_one=False)\n",
    "pipe = StableDiffusionPipeline.from_pretrained(model_path, scheduler=scheduler, safety_checker=None, torch_dtype=torch.float16).to(\"cuda\")\n",
    "\n",
    "g_cuda = torch.Generator(device='cuda')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182db074-2c5c-4dd3-8f6b-b6bf7f93e4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "3D animated illustration of yusufjkhan1 as young  disney pixar animated character : 4.0 |\n",
    "big disney eyes : 8.5 |\n",
    "disney 3D,\n",
    "big hero 6, up,\n",
    "young pixar,\n",
    "colorful cartoon,\n",
    "disney animated,\n",
    "pixar eyes,\n",
    "yusufjkhan1,\n",
    "disney,\n",
    "pixar, \n",
    "professional,\n",
    "bokeh,\n",
    "disney pixar\n",
    "\"\"\"\n",
    "\n",
    "prompt = \"\"\"\n",
    "yusufjkhan1 as a marble sculpture : 3.0 |\n",
    "background of museum : 1.5 |\n",
    "roman sculpture,\n",
    "muscular,\n",
    "muscles,\n",
    "robes,\n",
    "marble,\n",
    "marble statue,\n",
    "stone sculpture\n",
    "\"\"\"\n",
    "\n",
    "prompt = \"\"\"\n",
    "acrylic painting of yusufjkhan1 as a nomadic desert wanderer : 3.0 |\n",
    "painting,\n",
    "high definition,\n",
    "art,\n",
    "arab,\n",
    "bedouin,\n",
    "desert,\n",
    "camel,\n",
    "tribe\n",
    "\"\"\"\n",
    "\n",
    "prompt = \"\"\"\n",
    "colorful animated art of yusufjkhan1 as super saiyan from dragonball z : 3.0 |\n",
    "dragon ball z,\n",
    "yusufjkhan1,\n",
    "UHD,\n",
    "8k resolution,\n",
    "goku,\n",
    "vegeta,\n",
    "super saiyan,\n",
    "anime\n",
    "\"\"\"\n",
    "\n",
    "prompt = \"\"\"\n",
    "3D concept art of yusufjkhan1 as kratos from god of war : 3.0 |\n",
    "yusufjkhan1,\n",
    "ghost of sparta,\n",
    "play station,\n",
    "god of war\n",
    "\"\"\"\n",
    "\n",
    "prompt = \"\"\"\n",
    "animated drawing of yusufjkhan1 as character in Pirates of the Caribbean : 3.0 |\n",
    "with a pirate ship in the background : 2.0 |\n",
    "pirates of the caribbean,\n",
    "jack sparrow,\n",
    "pirates,\n",
    "captain barbossa\n",
    "\"\"\"\n",
    "\n",
    "prompt = \"\"\"\n",
    "cartoon animation of yusufjkhan1 as wolverine from the x-men : 3.0 |\n",
    "x men,\n",
    "yusufjkhan1,\n",
    "wolverine,\n",
    "highly detailed,\n",
    "high exposure\n",
    "\"\"\"\n",
    "\n",
    "negative_prompt = \"duplication, smile\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa96220-d770-4871-be96-a5017c7037d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 52365\n",
    "g_cuda.manual_seed(seed)\n",
    "num_samples = 6\n",
    "guidance_scale = 10\n",
    "num_inference_steps = 100\n",
    "height = 512 \n",
    "width = 512 \n",
    "\n",
    "with autocast(\"cuda\"), torch.inference_mode():\n",
    "    images = pipe(\n",
    "        prompt,\n",
    "        height=height,\n",
    "        width=width,\n",
    "        negative_prompt=negative_prompt,\n",
    "        num_images_per_prompt=num_samples,\n",
    "        num_inference_steps=num_inference_steps,\n",
    "        guidance_scale=guidance_scale,\n",
    "        generator=g_cuda\n",
    "    ).images\n",
    "\n",
    "for img in images:\n",
    "    display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2534641-65ac-4111-b295-343cb2cb5247",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = utils._get_config(utils.CONFIG_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "01274d50-5b32-4960-a122-a7812ed10d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaping encoder.mid.attn_1.q.weight for SD format\n",
      "Reshaping encoder.mid.attn_1.k.weight for SD format\n",
      "Reshaping encoder.mid.attn_1.v.weight for SD format\n",
      "Reshaping encoder.mid.attn_1.proj_out.weight for SD format\n",
      "Reshaping decoder.mid.attn_1.q.weight for SD format\n",
      "Reshaping decoder.mid.attn_1.k.weight for SD format\n",
      "Reshaping decoder.mid.attn_1.v.weight for SD format\n",
      "Reshaping decoder.mid.attn_1.proj_out.weight for SD format\n"
     ]
    }
   ],
   "source": [
    "model_checkpoints = Path(config['OUTPUT_DIR']).joinpath('1000', \"/model.ckpt\")\n",
    "weights_dir = Path(config['OUTPUT_DIR']).joinpath('1000')\n",
    "\n",
    "!python src/convert_diffusers_to_original_stable_diffusion.py --model_path $weights_dir --checkpoint_path $model_checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e48b3c2-a0c3-4a1d-8d8f-f75cc83b2deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "api = HfApi()\n",
    "load_dotenv()\n",
    "usr = api.whoami(token=os.getenv('hf_write'))[\"name\"]\n",
    "repo = \"sd-1-5-yusufjkhan1\"\n",
    "repo_id = f\"{usr}/{slugify(repo)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c4e3e0ef-53e6-4601-a6a2-0797de8cedec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33mUploading to HuggingFace : \u001b[0m|█████████████████████████| 100%\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Your concept was saved successfully. [Click here to access it](https://huggingface.co/BoiElroy/sd-1-5-yusufjkhan1)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def bar(prg):\n",
    "    br=\"\u001b[1;33mUploading to HuggingFace : \" '\u001b[0m|'+'█' * prg + ' ' * (25-prg)+'| ' +str(prg*4)+ \"%\"\n",
    "    return br\n",
    "\n",
    "print(\"\u001b[1;32mLoading...\")\n",
    "\n",
    "NM=\"False\"\n",
    "if os.path.getsize(str(weights_dir)+\"/text_encoder/pytorch_model.bin\") > 670901463:\n",
    "  NM=\"True\"\n",
    "\n",
    "\n",
    "if NM==\"False\":\n",
    "  with capture.capture_output() as cap:\n",
    "    %cd $weights_dir\n",
    "    !rm -r safety_checker feature_extractor .git\n",
    "    !rm model_index.json\n",
    "    !git init\n",
    "    !git lfs install --system --skip-repo\n",
    "    !git remote add -f origin  \"https://USER:{hf_token}@huggingface.co/runwayml/stable-diffusion-v1-5\"\n",
    "    !git config core.sparsecheckout true\n",
    "    !echo -e \"feature_extractor\\nsafety_checker\\nmodel_index.json\" > .git/info/sparse-checkout\n",
    "    !git pull origin main\n",
    "    !rm -r .git\n",
    "    %cd /notebooks/stable_diffusion_experiment\n",
    "    \n",
    "operations = [\n",
    "  CommitOperationAdd(path_in_repo=f\"model.ckpt\",path_or_fileobj=str(model_checkpoints))\n",
    "]\n",
    "\n",
    "api.create_commit(\n",
    "  repo_id=repo_id,\n",
    "  operations=operations,\n",
    "  commit_message=f\"Model Commit\",\n",
    "  token=os.getenv('hf_write')\n",
    ")\n",
    "\n",
    "weights_dir = str(weights_dir)\n",
    "\n",
    "if NM==\"False\":\n",
    "  api.upload_folder(\n",
    "    folder_path=weights_dir+\"/feature_extractor\",\n",
    "    path_in_repo=\"feature_extractor\",\n",
    "    repo_id=repo_id,\n",
    "    token=os.getenv('hf_write')\n",
    "  )\n",
    "\n",
    "clear_output()\n",
    "print(bar(4))\n",
    "\n",
    "if NM==\"False\":\n",
    "  api.upload_folder(\n",
    "    folder_path=weights_dir+\"/safety_checker\",\n",
    "    path_in_repo=\"safety_checker\",\n",
    "    repo_id=repo_id,\n",
    "    token=os.getenv('hf_write')\n",
    "  )\n",
    "\n",
    "clear_output()\n",
    "print(bar(8))\n",
    "\n",
    "\n",
    "api.upload_folder(\n",
    "  folder_path=weights_dir+\"/scheduler\",\n",
    "  path_in_repo=\"scheduler\",\n",
    "  repo_id=repo_id,\n",
    "  token=os.getenv('hf_write')\n",
    ")\n",
    "\n",
    "clear_output()\n",
    "print(bar(9))\n",
    "\n",
    "api.upload_folder(\n",
    "  folder_path=weights_dir+\"/text_encoder\",\n",
    "  path_in_repo=\"text_encoder\",\n",
    "  repo_id=repo_id,\n",
    "  token=os.getenv('hf_write')\n",
    ")\n",
    "\n",
    "clear_output()\n",
    "print(bar(12))\n",
    "\n",
    "api.upload_folder(\n",
    "  folder_path=weights_dir+\"/tokenizer\",\n",
    "  path_in_repo=\"tokenizer\",\n",
    "  repo_id=repo_id,\n",
    "  token=os.getenv('hf_write')\n",
    ")\n",
    "\n",
    "clear_output()\n",
    "print(bar(13))\n",
    "\n",
    "api.upload_folder(\n",
    "  folder_path=weights_dir+\"/unet\",\n",
    "  path_in_repo=\"unet\",\n",
    "  repo_id=repo_id,\n",
    "  token=os.getenv('hf_write')\n",
    ")\n",
    "\n",
    "clear_output()\n",
    "print(bar(21))\n",
    "\n",
    "api.upload_folder(\n",
    "  folder_path=weights_dir+\"/vae\",\n",
    "  path_in_repo=\"vae\",\n",
    "  repo_id=repo_id,\n",
    "  token=os.getenv('hf_write')\n",
    ")\n",
    "\n",
    "clear_output()\n",
    "print(bar(23))\n",
    "\n",
    "api.upload_file(\n",
    "  path_or_fileobj=weights_dir+\"/model_index.json\",\n",
    "  path_in_repo=\"model_index.json\",\n",
    "  repo_id=repo_id,\n",
    "  token=os.getenv('hf_write')\n",
    ")\n",
    "\n",
    "clear_output()\n",
    "print(bar(24))\n",
    "\n",
    "\n",
    "clear_output()\n",
    "print(bar(25))\n",
    "\n",
    "display_markdown(f'''## Your concept was saved successfully. [Click here to access it](https://huggingface.co/{repo_id})\n",
    "''', raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5629e606-49df-4a85-8c11-6a91a3e844cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
