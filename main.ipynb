{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa4fb0d8-74d4-414e-a41c-f2178a46b79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.utils as utils\n",
    "import torch\n",
    "from torch import autocast\n",
    "from diffusers import StableDiffusionPipeline, DDIMScheduler\n",
    "\n",
    "from IPython.display import display\n",
    "from slugify import slugify\n",
    "from huggingface_hub import HfApi, HfFolder, CommitOperationAdd\n",
    "from huggingface_hub import create_repo\n",
    "from IPython.display import display_markdown\n",
    "from IPython.display import clear_output\n",
    "from IPython.utils import capture\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "581add08-89b5-492e-8e7d-fca08c8ec4e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Workspace Setup Complete ===\n"
     ]
    }
   ],
   "source": [
    "utils.setup_workspace(config_file=\"src/configs/workspace_config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "703fc722-392c-4b26-8cbd-0b2002a360ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t`--num_processes` was set to a value of `1`\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--mixed_precision` was set to a value of `'no'`\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "For effortless bug reporting copy-paste your error into this form: https://docs.google.com/forms/d/e/1FAIpQLScPB8emS3Thkp66nvqwmjTEgxp8Y9ufuWTzFyr9kJ5AoI47dQ/viewform?usp=sf_link\n",
      "================================================================================\n",
      "/usr/local/lib/python3.9/dist-packages/bitsandbytes/cuda_setup/paths.py:27: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/usr/local/nvidia/lib64'), PosixPath('/usr/local/nvidia/lib')}\n",
      "  warn(\n",
      "/usr/local/lib/python3.9/dist-packages/bitsandbytes/cuda_setup/paths.py:105: UserWarning: /usr/local/nvidia/lib:/usr/local/nvidia/lib64 did not contain libcudart.so as expected! Searching further paths...\n",
      "  warn(\n",
      "/usr/local/lib/python3.9/dist-packages/bitsandbytes/cuda_setup/paths.py:27: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('443'), PosixPath('tcp'), PosixPath('//10.43.0.1')}\n",
      "  warn(\n",
      "/usr/local/lib/python3.9/dist-packages/bitsandbytes/cuda_setup/paths.py:27: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('module'), PosixPath('//matplotlib_inline.backend_inline')}\n",
      "  warn(\n",
      "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching /usr/local/cuda/lib64...\n",
      "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.6\n",
      "CUDA SETUP: Detected CUDA version 112\n",
      "CUDA SETUP: Loading binary /usr/local/lib/python3.9/dist-packages/bitsandbytes/libbitsandbytes_cuda112.so...\n",
      "/usr/local/lib/python3.9/dist-packages/diffusers/utils/deprecation_utils.py:35: FutureWarning: It is deprecated to pass a pretrained model name or path to `from_config`.If you were trying to load a scheduler, please use <class 'diffusers.schedulers.scheduling_ddpm.DDPMScheduler'>.from_pretrained(...) instead. Otherwise, please make sure to pass a configuration dictionary instead. This functionality will be removed in v1.0.0.\n",
      "  warnings.warn(warning + message, FutureWarning)\n",
      "Caching latents: 100%|██████████████████████████| 50/50 [00:06<00:00,  8.27it/s]\n",
      "Steps:  25%|███         | 250/1000 [01:34<04:33,  2.74it/s, loss=0.248, lr=1e-6]\n",
      "Fetching 15 files: 100%|█████████████████████| 15/15 [00:00<00:00, 30961.89it/s]\u001b[A\n",
      "/usr/local/lib/python3.9/dist-packages/diffusers/utils/deprecation_utils.py:35: FutureWarning: The configuration file of this scheduler: DDIMScheduler {\n",
      "  \"_class_name\": \"DDIMScheduler\",\n",
      "  \"_diffusers_version\": \"0.9.0\",\n",
      "  \"beta_end\": 0.012,\n",
      "  \"beta_schedule\": \"scaled_linear\",\n",
      "  \"beta_start\": 0.00085,\n",
      "  \"clip_sample\": false,\n",
      "  \"num_train_timesteps\": 1000,\n",
      "  \"prediction_type\": \"epsilon\",\n",
      "  \"set_alpha_to_one\": false,\n",
      "  \"steps_offset\": 0,\n",
      "  \"trained_betas\": null\n",
      "}\n",
      " is outdated. `steps_offset` should be set to 1 instead of 0. Please make sure to update the config accordingly as leaving `steps_offset` might led to incorrect results in future versions. If you have downloaded this checkpoint from the Hugging Face Hub, it would be very nice if you could open a Pull request for the `scheduler/scheduler_config.json` file\n",
      "  warnings.warn(warning + message, FutureWarning)\n",
      "\n",
      "Generating samples:   0%|                                 | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Generating samples:  25%|██████▎                  | 1/4 [00:04<00:13,  4.44s/it]\u001b[A\n",
      "Generating samples:  50%|████████████▌            | 2/4 [00:07<00:07,  3.64s/it]\u001b[A\n",
      "Generating samples:  75%|██████████████████▊      | 3/4 [00:10<00:03,  3.39s/it]\u001b[A\n",
      "Generating samples: 100%|█████████████████████████| 4/4 [00:13<00:00,  3.43s/it]\u001b[A\n",
      "[*] Weights saved at ./weights/250\n",
      "Steps:  30%|███▌        | 302/1000 [02:30<04:16,  2.72it/s, loss=0.244, lr=1e-6]\n",
      "Generating samples:   0%|                                 | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Generating samples:  25%|██████▎                  | 1/4 [00:03<00:09,  3.13s/it]\u001b[A\n",
      "Generating samples:  50%|████████████▌            | 2/4 [00:06<00:06,  3.09s/it]\u001b[A\n",
      "Generating samples:  75%|██████████████████▊      | 3/4 [00:09<00:03,  3.09s/it]\u001b[A\n",
      "Generating samples: 100%|█████████████████████████| 4/4 [00:12<00:00,  3.10s/it]\u001b[A\n",
      "[*] Weights saved at ./weights/500\n",
      "Steps:  75%|█████████   | 750/1000 [05:54<01:32,  2.72it/s, loss=0.248, lr=1e-6]\n",
      "Fetching 15 files: 100%|█████████████████████| 15/15 [00:00<00:00, 28493.91it/s]\u001b[A\n",
      "\n",
      "Generating samples:   0%|                                 | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Generating samples:  25%|██████▎                  | 1/4 [00:03<00:09,  3.12s/it]\u001b[A\n",
      "Generating samples:  50%|████████████▌            | 2/4 [00:06<00:06,  3.09s/it]\u001b[A\n",
      "Generating samples:  75%|██████████████████▊      | 3/4 [00:09<00:03,  3.10s/it]\u001b[A\n",
      "Generating samples: 100%|█████████████████████████| 4/4 [00:12<00:00,  3.10s/it]\u001b[A\n",
      "[*] Weights saved at ./weights/750\n",
      "Steps: 100%|███████████| 1000/1000 [08:02<00:00,  2.72it/s, loss=0.244, lr=1e-6]\n",
      "Fetching 15 files: 100%|█████████████████████| 15/15 [00:00<00:00, 33060.73it/s]\u001b[A\n",
      "\n",
      "Generating samples:   0%|                                 | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Generating samples:  25%|██████▎                  | 1/4 [00:03<00:10,  3.49s/it]\u001b[A\n",
      "Generating samples:  50%|████████████▌            | 2/4 [00:06<00:06,  3.45s/it]\u001b[A\n",
      "Generating samples:  75%|██████████████████▊      | 3/4 [00:10<00:03,  3.55s/it]\u001b[A\n",
      "Generating samples: 100%|█████████████████████████| 4/4 [00:13<00:00,  3.50s/it]\u001b[A\n",
      "[*] Weights saved at ./weights/1000\n",
      "Steps: 100%|███████████| 1000/1000 [08:56<00:00,  1.86it/s, loss=0.244, lr=1e-6]\n"
     ]
    }
   ],
   "source": [
    "!accelerate launch src/train_dreambooth.py \\\n",
    "  --pretrained_model_name_or_path=\"runwayml/stable-diffusion-v1-5\" \\\n",
    "  --pretrained_vae_name_or_path=\"stabilityai/sd-vae-ft-mse\" \\\n",
    "  --output_dir=\"./weights/\" \\\n",
    "  --revision=\"fp16\" \\\n",
    "  --with_prior_preservation --prior_loss_weight=1.0 \\\n",
    "  --seed=13278 \\\n",
    "  --resolution=512 \\\n",
    "  --train_batch_size=1 \\\n",
    "  --train_text_encoder \\\n",
    "  --mixed_precision=\"fp16\" \\\n",
    "  --use_8bit_adam \\\n",
    "  --gradient_accumulation_steps=1 \\\n",
    "  --learning_rate=1e-6 \\\n",
    "  --lr_scheduler=\"constant\" \\\n",
    "  --lr_warmup_steps=0 \\\n",
    "  --num_class_images=50 \\\n",
    "  --sample_batch_size=4 \\\n",
    "  --max_train_steps=1000 \\\n",
    "  --save_interval=250 \\\n",
    "  --save_sample_prompt=f\"concept art of {INSTANCE_NAME} {CLASS_NAME} as star wars character with sci-fi city in background, highly detailed, 8k, uhd, studio lighting, beautiful, high exposure, high contrast\" \\\n",
    "  --concepts_list=\"src/configs/concepts_list.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca169cd6-ccf1-4e6f-a7ee-fc4a52c086c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import autocast\n",
    "from diffusers import StableDiffusionPipeline, DDIMScheduler\n",
    "from IPython.display import display\n",
    "\n",
    "model_path = \"weights/1000/\"\n",
    "\n",
    "scheduler = DDIMScheduler(beta_start=0.00085, beta_end=0.012, beta_schedule=\"scaled_linear\", clip_sample=False, set_alpha_to_one=False)\n",
    "pipe = StableDiffusionPipeline.from_pretrained(model_path, scheduler=scheduler, safety_checker=None, torch_dtype=torch.float16).to(\"cuda\")\n",
    "\n",
    "g_cuda = torch.Generator(device='cuda')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "182db074-2c5c-4dd3-8f6b-b6bf7f93e4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "3D animated illustration of yusufjkhan1 as young  disney pixar animated character : 4.0 |\n",
    "big disney eyes : 8.5 |\n",
    "disney 3D,\n",
    "big hero 6, up,\n",
    "young pixar,\n",
    "colorful cartoon,\n",
    "disney animated,\n",
    "pixar eyes,\n",
    "yusufjkhan1,\n",
    "disney,\n",
    "pixar, \n",
    "professional,\n",
    "bokeh,\n",
    "disney pixar\n",
    "\"\"\"\n",
    "\n",
    "prompt = \"\"\"\n",
    "yusufjkhan1 as a marble sculpture : 3.0 |\n",
    "background of museum : 1.5 |\n",
    "roman sculpture,\n",
    "muscular,\n",
    "muscles,\n",
    "robes,\n",
    "marble,\n",
    "marble statue,\n",
    "stone sculpture\n",
    "\"\"\"\n",
    "\n",
    "prompt = \"\"\"\n",
    "acrylic painting of yusufjkhan1 as a nomadic desert wanderer : 3.0 |\n",
    "painting,\n",
    "high definition,\n",
    "art,\n",
    "arab,\n",
    "bedouin,\n",
    "desert,\n",
    "camel,\n",
    "tribe\n",
    "\"\"\"\n",
    "\n",
    "prompt = \"\"\"\n",
    "colorful animated art of yusufjkhan1 as super saiyan from dragonball z : 3.0 |\n",
    "dragon ball z,\n",
    "yusufjkhan1,\n",
    "UHD,\n",
    "8k resolution,\n",
    "goku,\n",
    "vegeta,\n",
    "super saiyan,\n",
    "anime\n",
    "\"\"\"\n",
    "\n",
    "prompt = \"\"\"\n",
    "3D concept art of yusufjkhan1 as kratos from god of war : 3.0 |\n",
    "yusufjkhan1,\n",
    "ghost of sparta,\n",
    "play station,\n",
    "god of war\n",
    "\"\"\"\n",
    "\n",
    "prompt = \"\"\"\n",
    "animated drawing of yusufjkhan1 as character in Pirates of the Caribbean : 3.0 |\n",
    "with a pirate ship in the background : 2.0 |\n",
    "pirates of the caribbean,\n",
    "jack sparrow,\n",
    "pirates,\n",
    "captain barbossa\n",
    "\"\"\"\n",
    "\n",
    "prompt = \"\"\"\n",
    "cartoon animation of yusufjkhan1 as character from disney movie Aladdin : 3.0 |\n",
    "disney,\n",
    "cartoon,\n",
    "2D,\n",
    "jaffar,\n",
    "aladdin,\n",
    "prince ali,\n",
    "genie\n",
    "\"\"\"\n",
    "\n",
    "prompt = \"\"\"\n",
    "cartoon animation yusufjkhan1 as an anime character from my hero academia : 4.0 |\n",
    "boku no hero academia, anime, brown skin, yusufjkhan1\n",
    "\"\"\"\n",
    "\n",
    "prompt = \"\"\"\n",
    "cartoon animation of yusufjkhan1 as wolverine from the x-men : 3.0 |\n",
    "x men,\n",
    "yusufjkhan1,\n",
    "wolverine,\n",
    "highly detailed,\n",
    "high exposure\n",
    "\"\"\"\n",
    "\n",
    "negative_prompt = \"duplication, smile\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa96220-d770-4871-be96-a5017c7037d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "229681bc0e2548a6a098742046eb921b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seed = 52364\n",
    "g_cuda.manual_seed(seed)\n",
    "num_samples = 6\n",
    "guidance_scale = 12\n",
    "num_inference_steps = 100\n",
    "height = 512 \n",
    "width = 512 \n",
    "\n",
    "with autocast(\"cuda\"), torch.inference_mode():\n",
    "    images = pipe(\n",
    "        prompt,\n",
    "        height=height,\n",
    "        width=width,\n",
    "        negative_prompt=negative_prompt,\n",
    "        num_images_per_prompt=num_samples,\n",
    "        num_inference_steps=num_inference_steps,\n",
    "        guidance_scale=guidance_scale,\n",
    "        generator=g_cuda\n",
    "    ).images\n",
    "\n",
    "for img in images:\n",
    "    display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2534641-65ac-4111-b295-343cb2cb5247",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = utils._get_config(utils.CONFIG_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "01274d50-5b32-4960-a122-a7812ed10d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaping encoder.mid.attn_1.q.weight for SD format\n",
      "Reshaping encoder.mid.attn_1.k.weight for SD format\n",
      "Reshaping encoder.mid.attn_1.v.weight for SD format\n",
      "Reshaping encoder.mid.attn_1.proj_out.weight for SD format\n",
      "Reshaping decoder.mid.attn_1.q.weight for SD format\n",
      "Reshaping decoder.mid.attn_1.k.weight for SD format\n",
      "Reshaping decoder.mid.attn_1.v.weight for SD format\n",
      "Reshaping decoder.mid.attn_1.proj_out.weight for SD format\n"
     ]
    }
   ],
   "source": [
    "ckpt_path = Path(config['OUTPUT_DIR']).joinpath('1000', \"/model.ckpt\")\n",
    "model_path = Path(config['OUTPUT_DIR']).joinpath('1000')\n",
    "\n",
    "!python src/convert_diffusers_to_original_stable_diffusion.py --model_path $model_path --checkpoint_path $ckpt_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e48b3c2-a0c3-4a1d-8d8f-f75cc83b2deb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
